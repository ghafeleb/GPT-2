{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ali\\Desktop\\gpt-2\\scriptsCPU times: total: 0 ns\n",
      "Wall time: 1min 16s\n",
      "\n",
      "c:\\Users\\Ali\\Desktop\\gpt-2\\scripts\n",
      "Running on cpu\n",
      "model_type: gpt2\n",
      "Loaded model!\n",
      "torch.Size([4, 32, 50257])\n",
      "tensor(10.9620, grad_fn=<NllLossBackward0>)\n",
      "Epoch 1, loss: 11.069896697998047\n",
      "Epoch 2, loss: 6.691137313842773\n",
      "Epoch 3, loss: 4.411059856414795\n",
      "Epoch 4, loss: 2.7389912605285645\n",
      "Epoch 5, loss: 1.5896186828613281\n",
      "Epoch 6, loss: 0.8843767642974854\n",
      "Epoch 7, loss: 0.49447715282440186\n",
      "Epoch 8, loss: 0.28351345658302307\n",
      "Epoch 9, loss: 0.18080806732177734\n",
      "Epoch 10, loss: 0.12094521522521973\n",
      "Epoch 11, loss: 0.08389722555875778\n",
      "Epoch 12, loss: 0.061154358088970184\n",
      "Epoch 13, loss: 0.04657919332385063\n",
      "Epoch 14, loss: 0.03646894171833992\n",
      "Epoch 15, loss: 0.03038286603987217\n",
      "Epoch 16, loss: 0.026429710909724236\n",
      "Epoch 17, loss: 0.023009994998574257\n",
      "Epoch 18, loss: 0.02000425010919571\n",
      "Epoch 19, loss: 0.01768866926431656\n",
      "Epoch 20, loss: 0.0159249696880579\n",
      "Epoch 21, loss: 0.014411654323339462\n",
      "Epoch 22, loss: 0.013000166974961758\n",
      "Epoch 23, loss: 0.011693897657096386\n",
      "Epoch 24, loss: 0.010544849559664726\n",
      "Epoch 25, loss: 0.009583230130374432\n",
      "Epoch 26, loss: 0.008794094435870647\n",
      "Epoch 27, loss: 0.008137768134474754\n",
      "Epoch 28, loss: 0.0075753130950033665\n",
      "Epoch 29, loss: 0.007079276721924543\n",
      "Epoch 30, loss: 0.0066312626004219055\n",
      "Epoch 31, loss: 0.0062224967405200005\n",
      "Epoch 32, loss: 0.005848485045135021\n",
      "Epoch 33, loss: 0.00550730898976326\n",
      "Epoch 34, loss: 0.005198794417083263\n",
      "Epoch 35, loss: 0.004921325948089361\n",
      "Epoch 36, loss: 0.004673060029745102\n",
      "Epoch 37, loss: 0.004450621549040079\n",
      "Epoch 38, loss: 0.0042512016370892525\n",
      "Epoch 39, loss: 0.004071654751896858\n",
      "Epoch 40, loss: 0.003908693324774504\n",
      "Epoch 41, loss: 0.003760161343961954\n",
      "Epoch 42, loss: 0.003623847384005785\n",
      "Epoch 43, loss: 0.0034983258228749037\n",
      "Epoch 44, loss: 0.0033822942059487104\n",
      "Epoch 45, loss: 0.003274790942668915\n",
      "Epoch 46, loss: 0.0031751280184835196\n",
      "Epoch 47, loss: 0.0030825056601315737\n",
      "Epoch 48, loss: 0.002996702678501606\n",
      "Epoch 49, loss: 0.002916984260082245\n",
      "Epoch 50, loss: 0.0028430938255041838\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python ../train/train_gpt2_test.py --train --data_type super_tiny_shakespear --lr 3e-4 --optimizer adam --epochs 50 --device cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ali\\Desktop\\gpt-2\\scriptsCPU times: total: 0 ns\n",
      "Wall time: 18 s\n",
      "\n",
      "c:\\Users\\Ali\\Desktop\\gpt-2\\scripts\n",
      "Running on cuda\n",
      "model_type: gpt2\n",
      "Loaded model!\n",
      "torch.Size([4, 32, 50257])\n",
      "tensor(10.9044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 1, loss: 10.797444343566895\n",
      "Epoch 2, loss: 8.212468147277832\n",
      "Epoch 3, loss: 7.389337062835693\n",
      "Epoch 4, loss: 14.134679794311523\n",
      "Epoch 5, loss: 9.839411735534668\n",
      "Epoch 6, loss: 9.718757629394531\n",
      "Epoch 7, loss: 7.567324638366699\n",
      "Epoch 8, loss: 7.265936374664307\n",
      "Epoch 9, loss: 7.108125686645508\n",
      "Epoch 10, loss: 6.968127250671387\n",
      "Epoch 11, loss: 6.801562309265137\n",
      "Epoch 12, loss: 6.583417892456055\n",
      "Epoch 13, loss: 6.325179576873779\n",
      "Epoch 14, loss: 6.058863639831543\n",
      "Epoch 15, loss: 5.807836532592773\n",
      "Epoch 16, loss: 5.577911853790283\n",
      "Epoch 17, loss: 5.3657708168029785\n",
      "Epoch 18, loss: 5.1638360023498535\n",
      "Epoch 19, loss: 4.9609832763671875\n",
      "Epoch 20, loss: 4.7524495124816895\n",
      "Epoch 21, loss: 4.547922611236572\n",
      "Epoch 22, loss: 4.3596696853637695\n",
      "Epoch 23, loss: 4.188434600830078\n",
      "Epoch 24, loss: 4.025635242462158\n",
      "Epoch 25, loss: 3.870269536972046\n",
      "Epoch 26, loss: 3.7275495529174805\n",
      "Epoch 27, loss: 3.573620319366455\n",
      "Epoch 28, loss: 3.4446871280670166\n",
      "Epoch 29, loss: 3.3341052532196045\n",
      "Epoch 30, loss: 3.225757598876953\n",
      "Epoch 31, loss: 3.1114768981933594\n",
      "Epoch 32, loss: 2.986755132675171\n",
      "Epoch 33, loss: 2.8670620918273926\n",
      "Epoch 34, loss: 2.755969285964966\n",
      "Epoch 35, loss: 2.695065498352051\n",
      "Epoch 36, loss: 2.648385524749756\n",
      "Epoch 37, loss: 2.792483329772949\n",
      "Epoch 38, loss: 2.7881009578704834\n",
      "Epoch 39, loss: 2.5653507709503174\n",
      "Epoch 40, loss: 2.421224355697632\n",
      "Epoch 41, loss: 2.3981497287750244\n",
      "Epoch 42, loss: 2.273942470550537\n",
      "Epoch 43, loss: 2.1156063079833984\n",
      "Epoch 44, loss: 2.042266607284546\n",
      "Epoch 45, loss: 1.949561595916748\n",
      "Epoch 46, loss: 1.8003616333007812\n",
      "Epoch 47, loss: 1.712831974029541\n",
      "Epoch 48, loss: 1.6749062538146973\n",
      "Epoch 49, loss: 1.5987941026687622\n",
      "Epoch 50, loss: 1.4898290634155273\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python ../train/train_gpt2_test.py --train --data_type super_tiny_shakespear --lr 3e-4 --optimizer adam --epochs 50 --device cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ali\\Desktop\\gpt-2\\scripts\n",
      "Running on cuda\n",
      "model_type: gpt2\n",
      "Loaded model!\n",
      "Loaded 338025 tokens\n",
      "1 epoch = 330 batches\n",
      "Epoch 1, loss: 10.924736022949219, Run time: 4215.00 ms\n",
      "Epoch 2, loss: 9.452760696411133, Run time: 204.00 ms\n",
      "Epoch 3, loss: 9.091828346252441, Run time: 195.00 ms\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 19.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ali\\anaconda3\\envs\\llm\\lib\\site-packages\\torch\\__init__.py:1073: UserWarning: 'high' is not one of 'highest', 'high', or 'medium'; the currentsetFloat32MatmulPrecision call has no effect. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\Context.cpp:244.)\n",
      "  _C._set_float32_matmul_precision(precision)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python ../train/train_gpt2.py --autocast_type 'bf16' --matmul_precision 'high' --batch_size 1 --token_size 1024 --train --data_type tiny_shakespear --lr 3e-4 --optimizer adam --epochs 3 --device cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ali\\Desktop\\gpt-2\\scripts\n",
      "Running on cuda\n",
      "model_type: gpt2\n",
      "args.compile_model: False\n",
      "Loaded model!\n",
      "Loaded 338025 tokens\n",
      "1 epoch = 330 batches\n",
      "Epoch 1, loss: 10.924736022949219, Run time: 1619.96 ms\n",
      "Epoch 2, loss: 9.452760696411133, Run time: 201.00 ms\n",
      "Epoch 3, loss: 9.091828346252441, Run time: 195.00 ms\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 9.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ali\\anaconda3\\envs\\llm\\lib\\site-packages\\torch\\__init__.py:1073: UserWarning: 'high' is not one of 'highest', 'high', or 'medium'; the currentsetFloat32MatmulPrecision call has no effect. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\Context.cpp:244.)\n",
      "  _C._set_float32_matmul_precision(precision)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python ../train/train_gpt2.py --autocast_type 'bf16' --matmul_precision 'high' --batch_size 1 --token_size 1024 --train --data_type tiny_shakespear --lr 3e-4 --optimizer adam --epochs 3 --device cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ali\\Desktop\\gpt-2\\scripts\n",
      "Running on cuda\n",
      "model_type: gpt2\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 3.86 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ali\\anaconda3\\envs\\llm\\lib\\site-packages\\torch\\__init__.py:1073: UserWarning: 'high' is not one of 'highest', 'high', or 'medium'; the currentsetFloat32MatmulPrecision call has no effect. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\Context.cpp:244.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Ali\\Desktop\\gpt-2\\train\\train_gpt2.py\", line 87, in <module>\n",
      "    main()\n",
      "  File \"c:\\Users\\Ali\\Desktop\\gpt-2\\train\\train_gpt2.py\", line 83, in main\n",
      "    model = get_model(args, device)\n",
      "  File \"c:\\Users\\Ali\\Desktop\\gpt-2\\train\\train_gpt2.py\", line 32, in get_model\n",
      "    model = model_class(GPTConfig())\n",
      "  File \"c:\\Users\\Ali\\Desktop\\gpt-2\\scripts\\..\\model\\gpt2.py\", line 228, in __init__\n",
      "    super().__init__()\n",
      "TypeError: GPT.__init__() missing 1 required positional argument: 'config'\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python ../train/train_gpt2.py --flash_attention --autocast_type 'bf16' --matmul_precision 'high' --batch_size 1 --token_size 1024 --train --data_type tiny_shakespear --lr 3e-4 --optimizer adam --epochs 3 --device cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
